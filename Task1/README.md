## Task_1a
Project 1a was a task based on cross-validation and ridge regression. The goal of the project was to determine the Root Mean Squared Error (RMSE) over 10 test folds of the dataset for a set of 5 specified regularization parameters. The dataset consisted of 150 samples and each sample had 13 attributes and 1 label/Y value associated with it. For the purpose of cross validation, the KFold function from sklearn module was utilized which outputs indices for splitting the training and testing data, which was then used to iterate through the dataset and the corresponding RMSE for each fold was determined. Subsequently, the above procedure was iterated for each of the 5 regularization parameters and the average RMSE for each regularization parameter was determined. On the public dataset in the evaluation server, the estimated RMSEs achieved a public score of approximately 13.6364. In addition, a random seed was introduced so that the results are reproducible.

## Task_1b
Project 1b was a task based on feature-transformations and regression. The goal of the project was to determine the optimal weight vector of our predictor and the evaluation metric for the prediction is RMSE. The dataset consisted of 700 samples and each sample had 5 attributes and 1 label/Y value associated with it. The feature transformations implied that the total number of features we will be using for fitting the model will be 21 and the weight vector will have 21 coefficients. For the purpose of estimating the most accurate model, multiple regression models namely Linear, Lasso and Ridge were tested with cross-validation, and to improve the model, the number of folds in the cross-validation section was also varied. The best model was determined to be a Ridge Regression Model with 10-fold cross validation and the optimal regularization parameter was determined to be 40. On the public dataset in the evaluation server, the developed model achieved a public score of approximately 2.0646. In efforts to improve the score on the public dataset, although some results with the LassoCV and RidgeCV achieved better scores on the training dataset, they were unsuccessful in surpassing the previous score on the public dataset. Alternative solutions such as preprocessing (standardizing) the dataset was considered to improve the accuracy of the model. However, this would have an impact on the coefficients of the weight vector and would lead to large errors on the public dataset.
